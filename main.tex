\documentclass{article} 

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage[b5paper, margin=1in]{geometry}
\usepackage[numbers]{natbib}
\usepackage{graphicx}
\usepackage{pgfplots}
\usepackage{tikz}
\usepackage{xcolor}

\newcommand{\R}{\mathbb R} 
\newcommand{\E}{\mathbb E} 
\newcommand{\dv}[2]{\frac{d #1}{d #2}}
\newcommand{\pdv}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\norm}[1]{\left\| #1 \right\| } 
\newcommand{\abs}[1]{\left| #1 \right| } 

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{research}{Research Question}

\title{Gradient Descent}
\author{Zachary Ross}

\begin{document}

\maketitle

In the following writeup, we explore gradient descent (GD) methods
and their convergence. These are adaptations to the general method
\begin{equation}
    \label{eq:gd}
    x_{t + 1} = x_t - \eta \nabla f(x_t),
\end{equation} where $\eta$ is the learning rate and $f: \R^n \rightarrow \R$ is
a \emph{convex} objective function with a unique minimum, which use previous
descent directions as part of current iterates computation. 


\tableofcontents

\pagebreak

\input{subjects/convergence.tex}
\input{subjects/acceleration.tex}
\input{subjects/first_order_methods.tex}

\bibliography{bib}
\bibliographystyle{plainnat}



\end{document}


